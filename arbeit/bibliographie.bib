las
https://www.asprs.org/wp-content/uploads/2019/03/LAS_1_4_r14.pdf
@article{las,
  title={The LAS 1.4 specification},
  author={Graham, Lewis},
  journal={Photogrammetric engineering and remote sensing},
  volume={78},
  number={2},
  pages={93--102},
  year={2012}
}

laszip
https://laszip.org/
http://wwwx.cs.unc.edu/~isenburg/lastools/download/laszip.pdf
@article{laz,
  title={LASzip: lossless compression of LiDAR data},
  author={Isenburg, Martin},
  journal={Photogrammetric engineering and remote sensing},
  volume={79},
  number={2},
  pages={209--217},
  year={2013},
  publisher={American Society of Photogrammetry}
}

lastools
https://github.com/LAStools/LAStools
https://www.isprs.org/PROCEEDINGS/XXXV/congress/comm2/papers/240.pdf
@inproceedings{lastools,
  title={Advanced Lidar Data Processing with Lastools},
  author={C. Hug and Peter Krzystek and Wolfgang Fuchs},
  year={2004},
  url={https://api.semanticscholar.org/CorpusID:14167994}
}

treeseg
https://github.com/apburt/treeseg
https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13121
@article{treeseg,
  author = {Burt, Andrew and Disney, Mathias and Calders, Kim},
  title = {Extracting individual trees from lidar point clouds using treeseg},
  journal = {Methods in Ecology and Evolution},
  volume = {10},
  number = {3},
  pages = {438-445},
  keywords = {extraction, forests, laser scanning, lidar, point cloud, segmentation, trees},
  doi = {https://doi.org/10.1111/2041-210X.13121},
  eprint = {https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13121},
  abstract = {Abstract Recent studies have demonstrated the potential of lidar-derived methods in plant ecology and forestry. One limitation to these methods is accessing the information content of point clouds, from which tree-scale metrics can be retrieved. This is currently undertaken through laborious and time-consuming manual segmentation of tree-level point clouds from larger-area point clouds, an effort that is impracticable across thousands of stems. Here, we present treeseg, an open-source software to automate this task. This method utilises generic point cloud processing techniques including Euclidean clustering, principal component analysis, region-based segmentation, shape fitting and connectivity testing. This data-driven approach uses few a priori assumptions of tree architecture, and transferability across lidar instruments is constrained only by data quality requirements. We demonstrate the treeseg algorithm here on data acquired from both a structurally simple open forest and a complex tropical forest. Across these data, we successfully automatically extract 96\% and 70\% of trees, respectively, with the remainder requiring some straightforward manual segmentation. treeseg allows ready and quick access to tree-scale information contained in lidar point clouds. treeseg should help contribute to more wide-scale uptake of lidar-derived methods to applications ranging from the estimation of carbon stocks through to descriptions of plant form and function.},
  year = {2019}
}

datensatz
https://doi.pangaea.de/10.1594/PANGAEA.942856?format=html#download
@misc{data,
 author={Hannah {Weiser} and Jannika {Sch\"{a}fer} and Lukas {Winiwarter} and Nina {Kra\v{s}ovec} and Christian {Seitz} and Marian {Schimka} and Katharina {Anders} and Daria {Baete} and Andressa Soarez {Braz} and Johannes {Brand} and Denis {Debroize} and Paula {Kuss} and Lioba Lucia {Martin} and Angelo {Mayer} and Torben {Schrempp} and Lisa-Maricia {Schwarz} and Veit {Ulrich} and Fabian E {Fassnacht} and Bernhard {H\"{o}fle}},
 title={{Terrestrial, UAV-borne, and airborne laser scanning point clouds of central European forest plots, Germany, with extracted individual trees and manual forest inventory measurements}},
 year={2022},
 doi={10.1594/PANGAEA.942856},
 url={https://doi.org/10.1594/PANGAEA.942856},
 abstract={Laser scanning point clouds of forest stands were acquired in southwest Germany in 2019 and 2020 from different platforms: an aircraft, an uncrewed aerial vehicle (UAV) and a ground-based tripod. The UAV-borne and airborne laser scanning campaigns cover twelve forest plots of approximately 1 ha. The plots are located in mixed central European forests close to Bretten and Karlsruhe, in the federal state of Baden-W\"{u}rttemberg, Germany. Terrestrial laser scanning was performed in selected locations within the twelve forest plots. Airborne and terrestrial laser scanning point clouds were acquired under leaf-on conditions, UAV-borne laser scans were acquired both under leaf-on and later under leaf-off conditions. In addition to the laser scanning campaigns, forest inventory tree properties (species, height, diameter at breast height, crown base height, crown diameter) were measured in-situ during summer 2019 in six of the twelve 1-ha plots. Single tree point clouds were extracted from the different laser scanning datasets and matched to the field measurements. For each tree entry, point clouds, tree species, position, and field-measured and point cloud-derived tree metrics are provided. For 249 trees, point clouds from all three platforms are available. The tree models form the basis of a single tree database covering a range of species typical for central European forests which is currently being established in the framework of the SYSSIFOSS project.},
 type={data set},
 publisher={PANGAEA}
}

eye-dome lighting
@article{eyedome,
  title={Eye-dome lighting: a non-photorealistic shading technique},
  author={Boucheny, C and Ribes, A},
  journal={Kitware Source Quarterly Magazine},
  volume={17},
  year={2011}
}

forest scan
@article{forestscan,
author = {Suzuki, Taro and Shiozawa, Shunichi and Yamaba, Atsushi and Amano, Yoshiharu},
year = {2021},
month = {05},
pages = {313-323},
title = {Forest Data Collection by UAV Lidar-Based 3D Mapping: Segmentation of Individual Tree Information from 3D Point Clouds},
volume = {15},
journal = {International Journal of Automation Technology},
doi = {10.20965/ijat.2021.p0313}
}


scan technoligies
@article{scantech,
  title={Adjudicating perspectives on forest structure: how do airborne, terrestrial, and mobile lidar-derived estimates compare?},
  author={Donager, Jonathon J and S{\'a}nchez Meador, Andrew J and Blackburn, Ryan C},
  journal={Remote Sensing},
  volume={13},
  number={12},
  pages={2297},
  year={2021},
  publisher={MDPI}
}

@article{terrestriallidar,
author = {Disney, Mathias},
title = {Terrestrial LiDAR: a three-dimensional revolution in how we look at trees},
journal = {New Phytologist},
volume = {222},
number = {4},
pages = {1736-1741},
keywords = {3D, canopy, function, light detection and ranging (LiDAR), structure, terrestrial laser scanning (TLS), tree},
doi = {https://doi.org/10.1111/nph.15517},
url = {https://nph.onlinelibrary.wiley.com/doi/abs/10.1111/nph.15517},
eprint = {https://nph.onlinelibrary.wiley.com/doi/pdf/10.1111/nph.15517},
abstract = {Contents Summary I. Introduction II. Terrestrial laser scanning III. Turning points into trees IV. Current and future applications of TLS V. Conclusions Acknowledgements References Summary Terrestrial laser scanning (TLS) is providing new, very detailed three-dimensional (3D) measurements of forest canopy structure. The information that TLS measurements can provide in describing detailed, accurate 3D canopy architecture offers fascinating new insights into the variety of tree form, environmental drivers and constraints, and the relationship between form and function, particularly for tall, hard-to-measure trees. TLS measurements are helping to test fundamental ecological theories and enabling new and better exploitation of other measurements and models that depend on 3D structural information. This Tansley insight introduces the background and capabilities of TLS in forest ecology, discusses some of the barriers to progress, and identifies some of the directions for new work.},
year = {2019}
}


FACHPRAKIKUM
% LTeX: enabled=false

https://www.cg.tuwien.ac.at/research/publications/2016/SCHUETZ-2016-POT/SCHUETZ-2016-POT-thesis.pdf
@mastersthesis{potree,
  abstract  = {This thesis introduces Potree, a web-based renderer for large point clouds. It allows users to view data sets with billions of points, from sources such as LIDAR or photogrammetry, in real time in standard web browsers. One of the main advantages of point cloud visualization in web browser is that it allows users to share their data sets with clients or the public without the need to install third-party applications and transfer huge amounts of data in advance. The focus on large point clouds, and a variety of measuring tools, also allows users to use Potree to look at, analyze and validate raw point cloud data, without the need for a time-intensive and potentially costly meshing step. The streaming and rendering of billions of points in web browsers, without the need to load large amounts of data in advance, is achieved with a hierarchical structure that stores subsamples of the original data at different resolutions. A low resolution is stored in the root node and with each level, the resolution gradually increases. The structure allows Potree to cull regions of the point cloud that are outside the view frustum, and to render distant regions at a lower level of detail. The result is an open source point cloud viewer, which was able to render point cloud data sets of up to 597 billion points, roughly 1.6 terabytes after compression, in real time in a web browser.},
  added-at  = {2021-12-10T13:27:33.000+0100},
  address   = {Favoritenstrasse 9-11/E193-02, A-1040 Vienna, Austria},
  author    = {Schuetz, Markus},
  biburl    = {https://www.bibsonomy.org/bibtex/21ad7fd6b77598e9c70162c7c4e92ec0a/abernstetter},
  interhash = {223d96c87cb132c3a60dabc56a32170f},
  intrahash = {1ad7fd6b77598e9c70162c7c4e92ec0a},
  keywords  = {pointclouds rendering visualization},
  month     = sep,
  school    = {Institute of Computer Graphics and Algorithms, Vienna               University of Technology },
  timestamp = {2021-12-10T13:27:33.000+0100},
  title     = {Potree: Rendering Large Point Clouds in Web Browsers},
  url       = {https://www.cg.tuwien.ac.at/research/publications/2016/SCHUETZ-2016-POT/},
  year      = 2016
}

https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6411672
@inproceedings{normal_pca,
  author    = {Nurunnabi, Abdul and Belton, David and West, Geoff},
  booktitle = {2012 International Conference on Digital Image Computing Techniques and Applications (DICTA)},
  title     = {Robust Segmentation in Laser Scanning 3D Point Cloud Data},
  year      = {2012},
  volume    = {},
  number    = {},
  pages     = {1-8},
  doi       = {10.1109/DICTA.2012.6411672}
}

https://www.cg.tuwien.ac.at/research/publications/2020/SCHUETZ-2020-MPC/SCHUETZ-2020-MPC-paper.pdf
@article{potree_lod,
  author   = {Schütz, Markus and Ohrhallinger, Stefan and Wimmer, Michael},
  title    = {Fast Out-of-Core Octree Generation for Massive Point Clouds},
  journal  = {Computer Graphics Forum},
  volume   = {39},
  number   = {7},
  pages    = {155-167},
  doi      = {https://doi.org/10.1111/cgf.14134},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14134},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14134},
  abstract = {Abstract We propose an efficient out-of-core octree generation method for arbitrarily large point clouds. It utilizes a hierarchical counting sort to quickly split the point cloud into small chunks, which are then processed in parallel. Levels of detail are generated by subsampling the full data set bottom up using one of multiple exchangeable sampling strategies. We introduce a fast hierarchical approximate blue-noise strategy and compare it to a uniform random sampling strategy. The throughput, including out-of-core access to disk, generating the octree, and writing the final result to disk, is about an order of magnitude faster than the state of the art, and reaches up to around 6 million points per second for the blue-noise approach and up to around 9 million points per second for the uniform random approach on modern SSDs.},
  year     = {2020}
}

https://github.com/PointCloudLibrary/pcl
@inproceedings{pcl,
  author    = {Radu Bogdan Rusu and Steve Cousins},
  title     = {{3D is here: Point Cloud Library (PCL)}},
  booktitle = {{IEEE International Conference on Robotics and Automation (ICRA)}},
  month     = {May 9-13},
  year      = {2011},
  address   = {Shanghai, China},
  publisher = {IEEE}
}

https://arxiv.org/pdf/1107.3013.pdf
@article{poisson_disk,
  author     = {Thouis R. Jones and David R. Karger},
  title      = {Linear-Time Poisson-Disk Patterns},
  journal    = {CoRR},
  volume     = {abs/1107.3013},
  year       = {2011},
  url        = {http://arxiv.org/abs/1107.3013},
  eprinttype = {arXiv},
  eprint     = {1107.3013},
  timestamp  = {Mon, 13 Aug 2018 16:48:09 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1107-3013.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

https://dl.acm.org/doi/pdf/10.1145/355578.366316
@article{eigenvalues_fast,
  author     = {Smith, Oliver K.},
  title      = {Eigenvalues of a Symmetric 3 x 3 Matrix},
  year       = {1961},
  issue_date = {April 1961},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {4},
  number     = {4},
  issn       = {0001-0782},
  url        = {https://doi.org/10.1145/355578.366316},
  doi        = {10.1145/355578.366316},
  abstract   = {Recently, in order to find the principal moments of inertia of a large number of rigid bodies, it was necessary to compute the eigenvalues of many real, symmetric 3 \texttimes{} 3 matrices. The available eigenvalue subroutines seemed rather heavy weapons to turn upon this little problem, so an explicit solution was developed. The resulting expressions are remarkably simple and neat, hence this note.},
  journal    = {Commun. ACM},
  month      = {apr},
  pages      = {168},
  numpages   = {1}
}

https://dl.acm.org/doi/pdf/10.1145/358669.358692
@article{ransac,
  author     = {Fischler, Martin A. and Bolles, Robert C.},
  title      = {Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography},
  year       = {1981},
  issue_date = {June 1981},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {24},
  number     = {6},
  issn       = {0001-0782},
  url        = {https://doi.org/10.1145/358669.358692},
  doi        = {10.1145/358669.358692},
  abstract   = {A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing},
  journal    = {Commun. ACM},
  month      = {jun},
  pages      = {381–395},
  numpages   = {15},
  keywords   = {location determination, camera calibration, image matching, automated cartography, scene analysis, model fitting}
}

https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4160265
@article{matplotlib,
  author  = {Hunter, John D.},
  journal = {Computing in Science \& Engineering},
  title   = {Matplotlib: A 2D Graphics Environment},
  year    = {2007},
  volume  = {9},
  number  = {3},
  pages   = {90-95},
  doi     = {10.1109/MCSE.2007.55}
}

@online{3di,
  author  = {{3DInteractive}},
  title   = {{Home - 3DInteractive}},
  year    = 2023,
  url     = {https://www.3dinteractive.de/},
  urldate = {2023-08-07}
}

https://www.sciencedirect.com/science/article/pii/S0921889008001140
@article{outlier,
title = {{Towards 3D Point cloud based object maps for household environments}},
journal = {Robotics and Autonomous Systems},
volume = {56},
number = {11},
pages = {927-941},
year = {2008},
note = {Semantic Knowledge in Robotics},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2008.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0921889008001140},
author = {Radu Bogdan Rusu and Zoltan Csaba Marton and Nico Blodow and Mihai Dolha and Michael Beetz},
keywords = {Environment object model, Point cloud data, Geometrical reasoning},
abstract = {This article investigates the problem of acquiring 3D object maps of indoor household environments, in particular kitchens. The objects modeled in these maps include cupboards, tables, drawers and shelves, which are of particular importance for a household robotic assistant. Our mapping approach is based on PCD (point cloud data) representations. Sophisticated interpretation methods operating on these representations eliminate noise and resample the data without deleting the important details, and interpret the improved point clouds in terms of rectangular planes and 3D geometric shapes. We detail the steps of our mapping approach and explain the key techniques that make it work. The novel techniques include statistical analysis, persistent histogram features estimation that allows for a consistent registration, resampling with additional robust fitting techniques, and segmentation of the environment into meaningful regions.}
}

@other{bachelor,
  title={{Hypergraph-Spektral-Ansatz zur Bearbeitung ungeordneter 3D-Punktewolken}},
  year={2022},
  author = {Anton Wetzel},
  school    = {Bachelorarbeit, Technische Universität Ilmenau},
}

@other{galileo,
  author  = {{Galileo-IP Ingenieure GmbH, Erlaubnis zur Nutzung der Autobahndaten an 3DInteractive GmbH erteilt}},
  year    = 2023,
}

@online{e57,
  author  = {{E57.04 3D Imaging System File Format Committee}},
  title   = {E57 Data Examples},
  year    = 2010,
  url     = {http://www.libe57.org/data.html},
  urldate = {2023-08-22}
}

https://dl.acm.org/doi/pdf/10.1145/366622.366647
@article{quickselect,
  author = {Hoare, C. A. R.},
  title = {Algorithm 65: Find},
  year = {1961},
  issue_date = {July 1961},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {4},
  number = {7},
  issn = {0001-0782},
  url = {https://doi.org/10.1145/366622.366647},
  doi = {10.1145/366622.366647},
  journal = {Commun. ACM},
  month = {jul},
  pages = {321–322},
  numpages = {2}
}

https://jcgt.org/published/0007/03/04/
@article{ray_aabb,
  author =       {Alexander Majercik and Cyril Crassin and Peter Shirley and Morgan McGuire},
  title =        {A Ray-Box Intersection Algorithm and Efficient Dynamic Voxel Rendering},
  year =         2018,
  month =        {September},
  day =          20,
  journal =      {Journal of Computer Graphics Techniques (JCGT)},
  volume =       7,
  number =       3,
  pages =        {66--81},
  url =          {http://jcgt.org/published/0007/03/04/},
  issn =         {2331-7418}
}


https://www.mdpi.com/1999-4907/6/11/4245
@Article{simple_tree,
AUTHOR = {Hackenberg, Jan and Spiecker, Heinrich and Calders, Kim and Disney, Mathias and Raumonen, Pasi},
TITLE = {SimpleTree —An Efficient Open Source Tool to Build Tree Models from TLS Clouds},
JOURNAL = {Forests},
VOLUME = {6},
YEAR = {2015},
NUMBER = {11},
PAGES = {4245--4294},
URL = {https://www.mdpi.com/1999-4907/6/11/4245},
ISSN = {1999-4907},
ABSTRACT = {An open source tool named SimpleTree, capable of modelling highly accurate cylindrical tree models from terrestrial laser scan point clouds, is presented and evaluated. All important functionalities, accessible in the software via buttons and dialogues, are described including the explanation of all necessary input parameters. The method is validated utilizing 101 point clouds of six different tree species, in the main evergreen and coniferous trees. All scanned trees have been destructively harvested to get accurate estimates of above ground biomass with which we assess the accuracy of the SimpleTree-reconstructed cylinder models. The trees were grouped into four data sets and for each one a Concordance Correlation Coefficient of at least 0.92 (0.92, 0.97, 0.92, 0.94) and an total relative error at most ~8 % (2.42%, 3.59%, –4.59%, 8.27%) was achieved in the comparison of the model results to the ground truth data. A global statistical improvement of derived cylinder radii is presented as well as an efficient optimization approach to automatically improve user given input parameters. An additional check of the SimpleTree results is presented via comparison to the results of trees reconstructed using an alternative, published method.},
DOI = {10.3390/f6114245}
}


https://ieeexplore.ieee.org/document/8462802
@ARTICLE{from_images,
  author={Guo, Jianwei and Xu, Shibiao and Yan, Dong-Ming and Cheng, Zhanglin and Jaeger, Marc and Zhang, Xiaopeng},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  title={Realistic Procedural Plant Modeling from Multiple View Images},
  year={2020},
  volume={26},
  number={2},
  pages={1372-1384},
  keywords={Three-dimensional displays;Solid modeling;Computational modeling;Image reconstruction;Shape;Geometry;Vegetation;Multi-view images;dense depth map;procedural modeling;plant reconstruction},
  doi={10.1109/TVCG.2018.2869784}}


https://dl.acm.org/doi/10.1145/3478513.3480486
@article{neural_decomp,
author = {Liu, Yanchao and Guo, Jianwei and Benes, Bedrich and Deussen, Oliver and Zhang, Xiaopeng and Huang, Hui},
title = {TreePartNet: neural decomposition of point clouds for 3D tree reconstruction},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3478513.3480486},
doi = {10.1145/3478513.3480486},
abstract = {We present TreePartNet, a neural network aimed at reconstructing tree geometry from point clouds obtained by scanning real trees. Our key idea is to learn a natural neural decomposition exploiting the assumption that a tree comprises locally cylindrical shapes. In particular, reconstruction is a two-step process. First, two networks are used to detect priors from the point clouds. One detects semantic branching points, and the other network is trained to learn a cylindrical representation of the branches. In the second step, we apply a neural merging module to reduce the cylindrical representation to a final set of generalized cylinders combined by branches. We demonstrate results of reconstructing realistic tree geometry for a variety of input models and with varying input point quality, e.g., noise, outliers, and incompleteness. We evaluate our approach extensively by using data from both synthetic and real trees and comparing it with alternative methods.},
journal = {ACM Trans. Graph.},
month = {dec},
articleno = {232},
numpages = {16},
keywords = {3D reconstruction, deep learning, geometric modeling, optimization, procedural generation, procedural modeling}
}